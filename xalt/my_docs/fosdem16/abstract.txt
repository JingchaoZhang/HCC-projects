Let’s talk real, no-kiddin’ supercomputer analytics, aimed at moving
beyond monitoring the machine as a whole or even its individual
hardware components. We’re interested in drilling down to the level of
individual batch submissions, users, and binaries. We’re after ready
answers to the "what, where, how, when and why" that stakeholders are
clamoring for – everything from which libraries (or individual
functions!) are in demand to preventing the problems that get in the
way of successful science. This talk will show how to set up the XALT
tool that can provide this type of job-level insight. 

The XALT tool can provide a wide range of metrics and measures of
job-level activity. There are benefits to users and stakeholders:
sponsoring institutions interested in strategic priorities;
organizations concerned about meeting users’ needs; and those seeking
to study user activity to improve value and effectiveness.

We will show how this tool provides high value to centers and
their users as it can provide documentation on how an application was
built to provide reproducibility.
